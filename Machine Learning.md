
# 机器学习基本概念

---

[toc]

---

## 1.机器学习

&emsp;&emsp;机器学习是实现人工智能的一种途径。其注重算法的设计，让计算机能够自动地从数据中“学习”规律，并利用规律对未知数据进行预测。因为学习算法和统计学联系紧密，所以也被称为统计学习方法。机器学习主要分为：监督学习、非监督学习和强化学习(半监督学习）。

![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/machine%20learning.jpg)

## 2.监督学习

&emsp;&emsp;监督学习涉及一组标记数据。计算机可以使用特定的模式来识别每种标记类型的新样本，从给定的训练数据集中学习出一个函数（模型参数）。当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求包括输入和输出，也可以说是特征和目标，训练集中的目标是由人标注的。监督学习常用于训练神经网络和决策树。

>监督学习两种主要类型

1. **分类**：机器被训练成将一个组划分为特定的类。分类的一个简单例子是电子邮件帐户上的垃圾邮件过滤器。

2. **回归**：机器使用先前的(标记的)数据来预测未知。天气应用是回归的好例子。

## 3. 非监督学习

&emsp;&emsp;输入数据没有被标记，样本数据类别未知，也没有确定的结果。需要根据样本间的相似性对样本集进行分类（聚类）试图使类内差距最小化、类间差距最大化。通俗点讲就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。

&emsp;&emsp;非监督学习目标不是告诉计算机怎么做，而是让它自己去学习怎样做事情。非监督学习有两种思路。其中一种思路是在指导agent时不为其指定明确分类，而是在成功时，采用某种形式的激励制度。需要注意的是，这类训练通常会置于决策问题的框架里，因为它的目标不是为了产生一个分类系统，而是做出最大回报的决定，这种思路很好的概括了现实世界，agent可以对正确的行为做出激励，而对错误行为做出惩罚。

>非监督学习两种主要类型

1. **基于概率密度函数估计的直接方法**：指设法找到各类别在特征空间的分布参数，再进行分类。

2. **基于样本间相似性度量的简洁聚类方法**：其原理是设法定出不同类别的核心或初始内核，然后依据样本与核心之间的相似性度量将样本聚集成不同的类别。

>监督学习和非监督学习之间的区别

1. **监督学习**训练数据既有特征又有标签。通过训练让机器找到特征和标签之间的联系，在面对只有特征没有标签的数据时，可以判断出标签。**非监督学习**不知道数据集中数据和特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。
2. **监督学习**必须有训练集和测试样本。在训练集中找规律，而对测试样本使用这种规律。而**非监督学习**没有训练集，只有一组数据，在该组数据集内寻找规律。
3. **监督学习**的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。**非监督学习**方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。

## 4. 半监督学习

&emsp;&emsp;半监督学习介于监督学习和非监督学习之间，它同时利用有标记样本与无标记样本进行学习。它所利用的数据集可以分为两部分，一部分是有标记的数据集，另一部分是无标记数据集，这部分数据集中样本点的类别标记未知。 与实际情况相符一般假设无标记数据远远多于有标记数据。

&emsp;&emsp;目前的机器学习技术大多基于独立同分布假设，即数据样本独立地采样于同一分布。除了独立同分布假设，为了学习到泛化的结果，监督学习技术大多基于平滑smoothness)假设，即相似或相邻的样本点的标记也应当相似。而在半监督学习中这种平滑假设则体现为两个较为常见的假设：聚类假设与流型假设。

>半监督学习中的基本假设

&emsp;&emsp;聚类假设：是指同一聚类中的样本点很可能具有同样的类别标记。这个假设可以通过另一种等价的方式进行表达，那就是决策边界所穿过的区域应当是数据点较为稀疏的区域，因为如果决策边界穿过数据点较为密集的区域那就很有可能将一个聚类中的样本点分为不同的类别这与聚类假设矛盾。

&emsp;&emsp;流型假设：是指高维中的数据存在着低维的特性。

## 5. 深度学习

[深度学习学习笔记整理](https://www.cnblogs.com/mfryf/p/5946883.html)

## 6. 强化学习

## 7. 深度强化学习

## 8. Q学习

## 9. 迁移学习

## 10. 迭代学习

&emsp;&emsp;迭代是为了实现某种结果而重复一组任务的过程。大多数书都按照正向顺序（sequential）讲解机器学习的过程：加载数据、预处理、拟合模型、预测等。这种顺序方法当然是合理和有帮助的，但现实的机器学习很少如此线性。相反，实用机器学习有一个特殊的循环（cyclical）性质，需要不断的迭代、调整和改进。

## 11. 全连接神经网络

>全连接神经网络：对n-1层和n层而言，n-1层的任意一个节点，都和第n层所有节点有连接。即第n层的每个节点在进行计算的时候，激活函数的输入是n-1层所有节点的加权。

>“全连接”是一种不错的连接方式，但是当网络很大时，训练速度很慢。部分连接解释认为的切断两个节点直接的连接，这样训练时计算量将会大大减小。

1. 组成：输入层、输出层、隐藏层(输入层、激活函数、全连接层)
   ![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/%E8%BE%93%E5%85%A5%E5%B1%82%E9%9A%90%E8%97%8F%E5%B1%82%E8%BE%93%E5%87%BA%E5%B1%82.jpg)
2. 同一层的神经元之间没有连接、每个连接都有一个权值
   ![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.jpg)
3. 一个神经元的组成为:
   * 输入：n维向量x
   * 线性加权：w是权值，b是偏置项
     ![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/%E5%B1%82%E5%8A%A0%E6%9D%83%E5%85%AC%E5%BC%8F.jpg)
   * 激活函数：H(x)，要求非线性，容易求导数
   * 输出：a
4. 神经网络的训练
   * 一个神经网络的每个连接上的权值；
   * 神经网络就是一个模型，这些权值就是模型的参数(即模型要学习的东西)；
   * 对于这个神经网络的连接方式、网络层数、每层的节点个数，这些是我们实现设置的，成为超参数。
5. 激活函数
   * 人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端
   * 激活函数将非线性特征引入到我们的网络中。在神经元中，输入的inputs通过加权求和后，还被作用了一个函数，这个函数就是激活函数。引入激活函数就是为了增加神经网络模型的非线性。没有激活函数的每层相当于矩阵相乘，即使叠加了若干层后，本质上还是矩阵的乘法。
   * 常见的激活函数
     * Sigmoid函数：f(x)=1/(1+e^(-x))；1).两头过于平坦(梯度更新十分缓慢，即梯度消失)；2).输出值域不对称(不是以0为均值)；3).该函数可以用在网络最后一层，作为输出层进行二分类，尽量不用在隐藏层
     * Tanh函数：f(x)=(e^x-e^(-x))/(e^x+e^(-x))；1).两头过于平坦(梯度更新十分缓慢，即梯度消失)
     * ReLU函数：f(x)=max(0,x)；1).当输入为整数时，不存在梯度小时的问题；2).当输入为负数时，会产生梯度消失问题；3).计算速度要快很多。
   * 如何选择激活函数：
     * 深度学习往往需要大量时间来处理数据，模型的收敛速度尤为重要。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。所以要尽量选择输出具有zero-centered特点的激活函数以加快模型的收敛速度。
     * 如果使用ReLU，那么一定要小心设置learning rate，而且要注意不要让网络出现很多"dead"神经元，如果这个问题不好解决，那么可以试试Leaky ReLU、PReLU或者Maxout。
     * 最好不要用sigmoid，你可以试试tanh，不过可以预期它的效果会比不上ReLU和Maxout。
   * Leaky ReLU函数
   * MaxOut函数
6. 损失函数

   >损失函数分为**经验风险损失函数**和**结构风险损失函数**，前者反映的是预测结果和实际结果之间的差别，后者则是经验风险损失函数加上正则项。

   * 损失函数是将随机事件或其有关随机变量的取值映射为非负数以表示该随机时间的风险或者损失的函数。在应用中，损失函数通常作为学习准则与优化问题相联系，即通过最小化损失函数求解和评估模型。

## 12. 卷积神经网络

>&emsp;&emsp;在全连接神经网络中，每两层之间的所有节点都有边相连。卷积神经网络也是通过一层一层的节点组织起来的，相邻两层之间只有部分节点相连。

>**[卷积神经网络是什么？](https://blog.csdn.net/kdongyi/article/details/82714988)**

>**[卷积神经网络——卷积层、池化层意义](https://blog.csdn.net/qq_30979017/article/details/79506593)**

1. 卷积神经网络的组成
   * **输入层**：输入层是整个神经网络的输入。在处理图像的卷积神经网络中，它一般代表一张图片的像素矩阵，三维矩阵的长和宽代表了图像的大小，而三维矩阵的深度代表了图像的色彩通道。从输入层开始，卷积神经网络通过不同的神经网络结构将上一层的三维矩阵转换成下一层的三维矩阵，直至最后的全连接层。
   * **卷积层**：和传统全连接层不同，卷积层中每个节点的输入只是上一层神经网络的一小块，这个小块常用的大小有3\*3或者5\*5。
   * **池化层(Pooling)**：池化层神经网络不会改变矩阵的深度，但是它可以缩小矩阵的大小。通过池化层可以进一步缩小最后全连接层中节点的个数，从而达到减少整个神经网络中参数的目的。
   * **全连接层**：在经过多轮卷积层和池化层的处理之后，在卷积神经网络的最后一般会是由一到两个全连接层来给出最后的分类结果。
   * **softmax层**：softmax层主要用于解决分类问题，通过softmax层，可以得到当前样例属于不同种类的概率分布情况。
   ![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90.png)
2. 卷积层
   * **卷积层的作用**：卷积层试图将神经网络中的每一小块进行更加深入的分析从而得到抽象程度更高的特征。一般来说通过卷积层处理过的节点矩阵会变得更深。
   * **过滤器**：卷积层神经网络中最重要的部分。(1).它是影像中不断移动的东西，不断在图片收集小批小批的像素块，收集完所有信息后，输出的值我们可以理解成是一个高度更高、长和宽更小的“图片”。这里的图片包含一些边缘信息。然后以同样的步骤再进行多次卷积，将图片的长宽再压缩，高度再增加，就有了对输入图片更深的理解。将压缩、增高的信息嵌套在普通的分类神经层上，我们就能对这种图片分类。(2).过滤器所处理节点矩阵的长、宽、深度都需要人工指定。
   * 在卷积神经网络中，每一个卷积层使用的过滤器的参数是一样的。共享过滤器参数可以使得图像上的内容不受位置的影响，还可以巨幅减少神经网络上的参数。所以卷积层的参数个数要远远小于全连接层。而且卷积层的参数个数和图片的大小无关，它只和过滤器的尺寸、深度以及当前节点矩阵的深度有关。
3. 池化层
   * 在卷积层之间往往会加上一个池化层，池化层可以非常有效的减少矩阵的尺寸（主要用于减少矩阵的长和宽，实践中一般不用来减少矩阵深度），从而有效减少最后全连接层中的参数。所以池化层可以既加快计算速度还可以防止过拟合。
   * **池化层的作用**： 在每一次卷积的时候，神经层可能会无意地丢失一些信息，池化可以很好地解决这一问题。池化是一个筛选过滤的过程，能将层中有用的信息筛选出来，给下一个层分析，减轻神经网络的计算负担。在卷积的时候，我们不压缩长和宽，尽量的保留更多信息，压缩的工作就交给池化，这样的一项附加工作能够很有效的提高准确性。主要用于特征降维、压缩数据和参数的数量，减小过拟合，同时提高模型的容错性。
   * 池化层滤器中的计算不是节点的加权和，而是采用更加简单的最大值或者平均值计算。使用最大值操作的池化层被称为最大池化层，使用平均值操作的池化层被称为平均池化层。
   * 池化层过滤器所处理节点矩阵的长和宽都需要人工设定。卷积层和池化层中过滤器的移动方式是相似的，唯一的区别在于卷积层使用的过滤器是横跨整个深度的，而池化层使用的过滤器只影响一个深度上的节点。所以池化层的过滤器除了在长和宽两个维度上移动之外，它还需要在深度这个维度上移动。
   ![](https://raw.githubusercontent.com/Jensen1026/Pictures/master/Mechine%20Learning/%E6%B1%A0%E5%8C%96%E5%B1%82.png)

4. 过拟合、欠拟合
   * 过拟合：机器对样本属性学习过于严格，并且学习了样本特有的属性，对模型未来应用到真实的判定系统时带来较大误差
     * 特征维度过多，导致拟合的函数完美的经过训练集，但是对新数据的预测结果则较差
     * 解决办法：(1).减少特征维度，可以人工选择保留的特征，或者模型选择算法；(2).正则化，保留所有的特征，提高降低参数θ的值来影响模型
   * 欠拟合：算法模型只学习了样本的少部分特征，不足以支撑判断，导致在真实应用中产生很多错误的预测
     * 原因：特征维度过少，导致拟合的函数无法满足训练集，误差较大
     * 解决办法：增加特征维度

## 13. 深度残差网络

## 14. 马尔可夫决策过程

## 15. 梯度下降法

>梯度下降法是一个一阶最优化算法，通常也称为最优下降法。要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或近似梯度）的反方向的规定步长距离点进行迭代搜索。如果相反地向梯度正方向迭代进行搜索，则会接近函数的局部极大值点，这个过程则被称为梯度上升法。

1. 描述：点向梯度下降的方向移动，同高数知识点
2. 相关概念
   * 步长：在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。
   * 特征：指的是样本输入部分
   * 假设函数：在监督学习中，为了拟合输入样本而使用的假设函数
   * 损失函数：为了评估模型拟合的好坏，通常用损失函数老度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。
3. 缺点
   * 靠近极小值时速度减慢
   * 梯度下降不一定能找到全局的最优解，有可能是一个局部最优解。如果损失函数是凸函数，梯度下降法得到的截一定是全局最优解。
4. 分类
   * **批量梯度下降法**：在更新参数时使用所有的样本来进行更新(有m个样本则求梯度时就用了所有m个样本的梯度数据)
   * **随机梯度下降法**：其实和批量梯度下降法原理类似，区别在与求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。
     * 随机梯度下降法和批量梯度下降法是两个极端，一个采用所有数据来梯度下降，一个用一个样本来梯度下降。自然各自的优缺点都非常突出。对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。
   * **小批量梯度下降法**：批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于m个样本，我们采用x个样本来迭代(1<x<m)。一般可以取x=10，根据样本的数据可以调整这个值。
5. 无约束优化算法：梯度下降法、最小二乘法、牛顿法、拟牛顿法
   * 牛顿法/拟牛顿法使用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快，但是每次迭代的时间比梯度下降法长。

## 16. 策略梯度的深度强化学习

[强化学习——基于策略梯度的强化学习算法](https://blog.csdn.net/weixin_41679411/article/details/82414400)

[策略梯度的深度强化学习](https://www.baidu.com/baidu?tn=monline_3_dg&ie=utf-8&wd=%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)

## SVM

## 17. 经验回放机制

## 18. 注意力机制

## 19. 反馈控制

## 20. A3C算法
